# -*- coding: utf-8 -*-
"""AutoTsTimeSeries.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1bJ4VHNnWCYk4KpmjBOnUng8lFhjYXq5Q
"""

import yfinance as yf
import pandas as pd
from datetime import datetime

# Function to fetch S&P 500 stock data from Yahoo Finance for the last 10 years
def fetch_sp500_data():

    sp500_tickers = ['AAPL', 'MSFT', 'GOOGL', 'AMZN', 'META']
    #sp500_tickers = ['^GSPC']
    # Define the date range (last 10 years)
    end_date = datetime.now().strftime('%Y-%m-%d')
    start_date = (datetime.now() - pd.DateOffset(years=10)).strftime('%Y-%m-%d')

    # Create an empty DataFrame to hold all stock data
    all_stock_data = pd.DataFrame()

    # Loop through the tickers and fetch their data
    for ticker in sp500_tickers:
        print(f"Fetching data for {ticker}")
        try:
            # Fetch the stock data for each ticker
            stock_data = yf.Ticker(ticker).history(start=start_date, end=end_date,interval='1wk')
            stock_data['Ticker'] = ticker  # Add a column for the ticker
            all_stock_data = pd.concat([all_stock_data, stock_data])
        except Exception as e:
            print(f"Could not fetch data for {ticker}: {e}")

    return all_stock_data

# Fetch the data and use it as a DataFrame
sp500_data = fetch_sp500_data()


# Show a summary of the data
print(sp500_data.head())

# Check the DataFrame structure for time series modeling
print(sp500_data.info())

"""Closing price should have the highest error rate matrix.
what models to use
weight of the models
Metric weigths.
"""

def get_single_stock_data(stock_data, ticker):
    # Filter the data to return only the rows for the specific ticker
    single_stock_data = stock_data[stock_data['Ticker'] == ticker]
    return single_stock_data

#single_stock_data = get_single_stock_data(sp500_data, 'AAPL')

single_stock_original_data = get_single_stock_data(sp500_data, 'AAPL')

single_stock_original_data

#single_stock_data = single_stock_original_data.groupby('Ticker').resample('W').last().reset_index(level=0, drop=True).reset_index()

!pip install autots

from autots import AutoTS
#from autots.datasets import load_hourly

def run_autots_forecast(df, forecast_length, model_list, weights, freq='W'):

    model = AutoTS(
        forecast_length=forecast_length,
        frequency=freq,
        prediction_interval=0.95,
        ensemble=['simple', 'horizontal-min'],
        max_generations=5,
        num_validations=0,
        #validation_method='seasonal 168',
        validation_method='backwards',
        model_list=model_list,

        transformer_list='all',
        models_to_validate=0.2,
        drop_most_recent=0,
        n_jobs='auto',
    )

    # Fit the model with the provided data and weights
    model = model.fit(
        df,
        weights=weights,
    )

    # Make predictions
    prediction = model.predict()

    # Return the forecast dataframe
    return prediction.forecast,model


# Custom model list
selected_model_list = [
    'NVAR',
    'MultivariateRegression',
    'MAR',
    'NeuralForecast'
]


all_model_list = [
    'MultivariateRegression',
    'GLS',
    'ETS',
    'AverageValueNaive',
    'DynamicFactorMQ',
    'PytorchForecasting',
    'NVAR',
    'NeuralForecast',
    'MAR',
    'RollingRegression',
    'BallTreeMultivariateMotif'
]


# Weights assigned to the time series columns
weights = {
    'Open': 3,     # Less focus on the starting point of the day
    'Close': 4,    # Lower, since breakouts are more dynamic
    'Low': 1,      # Keep balanced for downtrend volatility
    'High': 2,     # Important for detecting breakout points
}

# forecast_length

single_stock_data = single_stock_original_data.head(len(single_stock_original_data)-4)
forecast_results,model = run_autots_forecast(df=single_stock_data, forecast_length=7, model_list=selected_model_list, weights=weights)

# Show results
print(forecast_results)

forecast_results.to_csv('forecast_results.csv')

results = model.results()
best_model = model.best_model

print(best_model['ID'])
# metrics_df = results.model_performance

#print(results)

# Extract the single value from the Series
best_model_ids = best_model['ID'].iloc[0]  # Or use best_model_id.values[0] to get the scalar


# Now filter the results based on the best_model_id
best_model_results = results[results['ID'] == best_model_ids]

# Print all metrics for the best model
print(best_model_results)

results['ID']

import json

# Parse the 'ModelParameters' column and extract unique model names which were used for the prediction
unique_models = set()

for _, row in best_model.iterrows():
    print("Ensemble Model:")
    model_parameters = json.loads(row['ModelParameters'])

    # Access individual models
    models = model_parameters['models']
    for model_id, details in models.items():
        model_name = details['Model']

        if model_name != 'Ensemble' and model_name not in unique_models:
            unique_models.add(model_name)

            print(f"  Model Name: {model_name}")

print((best_model_results.columns))

best_model_results.to_csv('best_model_results.csv')

best_model_results['mae_weighted']

melted_df = best_model_results.melt(
      # Keep 'ID' and 'Model' as is
    value_vars=['smape_weighted', 'mae_weighted', 'rmse_weighted', 'made_weighted',
                'mage_weighted', 'mate_weighted', 'matse_weighted',
                'underestimate_weighted', 'mle_weighted', 'overestimate_weighted',
                'rmse', 'mae'],  # Columns to convert into rows
    var_name='Metric',          # New column name for metrics
    value_name='Value'          # New column name for metric values
)

# Print the transformed DataFrame
print(melted_df)

best_model_results = best_model_results[['ID','Model','smape_weighted',
       'mae_weighted', 'rmse_weighted', 'made_weighted', 'mage_weighted',
       'mate_weighted', 'matse_weighted', 'underestimate_weighted',
       'mle_weighted', 'overestimate_weighted','rmse','mae']]



best_model_results.to_excel('best_model.xlsx', index=False)

# Import Pandas
import pandas as pd

# Get the ensemble's model weights
#ensemble_weights = model.best_model['model_params']['Ensemble']['ensemble_weights']

# Access the 'Ensemble' column in the best model parameters
ensemble_info = model.best_model['Ensemble']
print("Ensemble Details:")
print(ensemble_info)

#print(ensemble_weights)

# Retrieve all models and their metrics
results = model.results()

# Look up the model corresponding to the ensemble selection
selected_model = results.loc[90]  # Use the ID from the Ensemble Details
print("Selected Model Details:")
print(selected_model)

selected_model['ModelParameters']

print(best_model_results['rmse'])
best_model_results['rmse_weighted']

# Ensure timezone removal for each datetime column individually
for col in best_model_results.select_dtypes(['datetime64[ns, UTC]']).columns:
    best_model_results[col] = best_model_results[col].dt.tz_localize(None)

# Write to Excel

a = results['ID'] == 214

metrics_df.to_csv('metrics_df.csv')

single_stock_original_data.to_csv('single_stock_original_data.csv')

single_stock_data.tail(3)
single_stocks_data = single_stock_original_data.head(len(single_stock_original_data)-4)
single_stocks_data.tail(3)

import plotly.graph_objects as go

# Assuming 'forecast_results' is a DataFrame with the forecasted values

def plot_forecast_plotly(forecast_df, original_data_df, forecast_length):


    # Get the original 'Close' column from the original data (you can choose others like 'Open', 'High', etc.)
    original_close = original_data_df['Close'].tail(100)

    # Ensure the forecast_df and original data match in columns
    forecast_close = forecast_df['Close']

    # Create a figure object
    fig = go.Figure()

    # Add the original close prices trace
    fig.add_trace(go.Scatter(
        x=original_close.index,
        y=original_close,
        mode='lines+markers',
        name='Original Close Prices',
        marker=dict(size=8, color='blue'),
        line=dict(width=2, color='blue')
    ))

    # Add the forecast close prices trace
    fig.add_trace(go.Scatter(
        x=forecast_close.index,
        y=forecast_close,
        mode='lines+markers',
        name='Forecasted Close Prices',
        marker=dict(size=10, color='orange', symbol='x'),
        line=dict(width=2, dash='dash', color='orange')
    ))

    # Update layout for professional styling
    fig.update_layout(
        title='Original vs Forecasted Close Prices',
        xaxis_title='Date',
        yaxis_title='Close Price',
        legend_title='Legend',
        font=dict(family="Arial, sans-serif", size=14),
        xaxis=dict(showgrid=True, gridwidth=1, gridcolor='LightGray', showline=True, linewidth=2, linecolor='black'),
        yaxis=dict(showgrid=True, gridwidth=1, gridcolor='LightGray', showline=True, linewidth=2, linecolor='black'),
        plot_bgcolor='white',
        hovermode='x unified'
    )

    # Show the plot
    fig.show()

# Call the Plotly plot function with forecast results and original data
forecast_results.index += pd.DateOffset(days=1)
plot_forecast_plotly(forecast_df=forecast_results, original_data_df=single_stock_original_data, forecast_length=3)

forecast_results.head()

#!pip install autots
from autots import AutoTS
model = AutoTS()


multivariate_models = model.model_list
print(multivariate_models)

from autots.models.model_list import model_lists

print((model_lists['multivariate']))

"""Model Information:

Let's break down how each of the models you mentioned—`DynamicFactorMQ`, `PytorchForecasting`, `MultivariateRegression`, `NVAR`, `NeuralForecast`, `MAR`, `RollingRegression`, and `BallTreeMultivariateMotif`—can affect stock market predictions, especially using a **multivariate time series** approach. I'll discuss their **advantages** and **disadvantages** in the context of stock price prediction.

---

### 1. **DynamicFactorMQ**
   - **Overview**: A statistical model used for multivariate time series forecasting. It's based on the Dynamic Factor Model (DFM) but extended with mixed frequencies (MQ) to handle datasets that have variables measured at different frequencies (e.g., daily stock prices, quarterly earnings reports).
   
   - **Advantages**:
     - **Mixed Frequencies**: Handles variables with different frequencies (daily, weekly, monthly), which is often the case in stock market data (price, volume, macroeconomic indicators).
     - **Latent Factor Modeling**: Can capture common trends across multiple time series (e.g., market-wide shocks).
     - **Good for Noise Reduction**: Filters out noise and focuses on key underlying factors affecting stock movements.
   
   - **Disadvantages**:
     - **High Complexity**: Complex to implement and requires careful tuning, especially with large datasets.
     - **Slow with Large Data**: Can be slow to estimate with a lot of variables.
     - **May Not Capture Non-linearities**: Purely statistical models like DFM often struggle with complex non-linear dynamics in stock prices.

---

### 2. **PytorchForecasting**
   - **Overview**: A deep learning-based forecasting library built on PyTorch, capable of handling both univariate and multivariate time series using neural networks.
   
   - **Advantages**:
     - **Highly Flexible**: Allows the use of advanced neural architectures (e.g., LSTMs, GRUs, Temporal Fusion Transformers) for time series forecasting.
     - **Deep Learning Power**: Good at capturing non-linear relationships in stock prices and interactions between multiple time series (e.g., prices, volumes, economic factors).
     - **Automatic Feature Extraction**: Handles complex feature extraction and learns temporal dependencies effectively.

   - **Disadvantages**:
     - **High Computational Cost**: Requires significant computational power and training time, especially for large datasets.
     - **Overfitting Risk**: Can easily overfit if not carefully tuned, especially on volatile and noisy stock market data.
     - **Black Box**: Harder to interpret compared to traditional statistical models (lack of transparency in decision-making).

---

### 3. **MultivariateRegression**
   - **Overview**: This is a traditional regression model that extends linear regression to multiple variables, using the relationships between multiple time series to predict future values.
   
   - **Advantages**:
     - **Simplicity**: Easy to understand, implement, and interpret.
     - **Fast**: Computationally efficient, even with large datasets.
     - **Good for Linear Trends**: Effective if stock market data exhibit linear relationships between different time series (e.g., stock prices and economic indicators).

   - **Disadvantages**:
     - **Limited to Linear Relationships**: Cannot capture non-linear dependencies, which are common in financial markets.
     - **Misses Complex Interactions**: Fails to account for more complex relationships between time series (e.g., stock price correlations).
     - **Vulnerable to Overfitting**: Can overfit if the model is too complex, especially with highly volatile data.

---

### 4. **NVAR (Nonlinear Vector Autoregression)**
   - **Overview**: NVAR is a variant of traditional vector autoregression (VAR) but focuses on capturing non-linear relationships between multiple time series.
   
   - **Advantages**:
     - **Non-linear Modeling**: Captures non-linear dependencies between variables, which are important in the stock market (e.g., price-volume interactions).
     - **Multi-Asset**: Can model multiple assets' prices simultaneously, accounting for cross-asset correlations.
     - **Good for Complex Markets**: Works well in markets with non-linear patterns and relationships (e.g., sudden crashes, rallies).

   - **Disadvantages**:
     - **Model Complexity**: Complex to implement and interpret compared to traditional VAR models.
     - **Data Hungry**: Requires large amounts of data for effective training.
     - **Risk of Overfitting**: Non-linear models are prone to overfitting, particularly in volatile financial markets.

---

### 5. **NeuralForecast**
   - **Overview**: A class of neural network models designed for time series forecasting, particularly suited for complex and non-linear patterns.
   
   - **Advantages**:
     - **Non-linear Dependencies**: Great for capturing non-linear and complex relationships in stock market data.
     - **Scalability**: Can scale to handle multiple assets and indicators, learning from their interactions.
     - **Long-term Dependencies**: Neural networks like LSTM and GRU can capture long-term dependencies in financial time series.

   - **Disadvantages**:
     - **Requires Careful Tuning**: Neural networks require careful hyperparameter tuning, which can be time-consuming.
     - **Computationally Intensive**: Neural networks are resource-heavy, requiring powerful hardware and long training times.
     - **Risk of Overfitting**: Similar to other deep learning models, neural networks can overfit, particularly in noisy, high-frequency financial data.

---

### 6. **MAR (Multivariate Adaptive Regression)**
   - **Overview**: A flexible regression technique that adapts to the underlying data patterns, often used for modeling complex, non-linear relationships.
   
   - **Advantages**:
     - **Adapts to Data**: Can model complex, non-linear relationships that exist in stock market data.
     - **Interpretable**: More interpretable than deep learning models, allowing analysts to understand how variables affect stock prices.
     - **Good for Noisy Data**: Handles noisy time series well by adapting to local data characteristics.

   - **Disadvantages**:
     - **Limited Flexibility**: Though more flexible than traditional regression, it may still miss very complex dynamics found in neural network models.
     - **Slow for Large Datasets**: Can be computationally slow for large multivariate datasets, common in stock market analysis.
     - **Not State-of-the-art**: Lags behind cutting-edge machine learning techniques in predictive power.

---

### 7. **RollingRegression**
   - **Overview**: A regression model applied over a rolling window, recalculating parameters as new data comes in.
   
   - **Advantages**:
     - **Handles Changing Relationships**: Useful in stock markets where relationships between variables change over time (e.g., due to market conditions).
     - **Simplicity**: Simple to understand and implement.
     - **Adapts Over Time**: Rolling window approach helps adapt to new market trends and price patterns.

   - **Disadvantages**:
     - **Limited by Window Size**: The choice of window size is critical and may lead to instability in predictions if not carefully chosen.
     - **Fails with Non-linear Data**: Like traditional regression, rolling regression struggles with capturing non-linearities.
     - **Short-term Focus**: Tends to focus on short-term trends, which might miss long-term market dynamics.

---

### 8. **BallTreeMultivariateMotif**
   - **Overview**: A time-series motif discovery method using a BallTree structure to efficiently find similar patterns (motifs) across multiple time series.
   
   - **Advantages**:
     - **Pattern Discovery**: Can discover recurring patterns in stock price movements, which can be useful for identifying trends or anomalies.
     - **Efficient Search**: BallTree-based search makes it computationally efficient for finding motifs in large datasets.
     - **Multivariate Focus**: Handles multiple time series, allowing for cross-series motif discovery.

   - **Disadvantages**:
     - **Pattern Dependency**: Relies on the assumption that patterns repeat, which may not always hold true in chaotic stock markets.
     - **Less Focus on Forecasting**: More suited for motif discovery and pattern recognition than direct forecasting.
     - **Not Suitable for Volatile Markets**: Struggles in highly volatile markets where patterns rarely repeat consistently.

---

### Summary of Each Model's Impact on Stock Market Prediction:

| **Model**                  | **Advantages**                                                                                  | **Disadvantages**                                                              |
|----------------------------|------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------|
| **DynamicFactorMQ**         | Handles mixed frequencies, captures common factors                                             | High complexity, struggles with non-linearities                                |
| **PytorchForecasting**      | Powerful deep learning, captures non-linearities                                               | Computationally expensive, risk of overfitting                                 |
| **MultivariateRegression**  | Simple, fast, interpretable                                                                    | Limited to linear relationships, misses complex interactions                   |
| **NVAR**                    | Captures non-linear relationships, good for multi-asset correlations                           | Complex, data-hungry, prone to overfitting                                     |
| **NeuralForecast**          | Learns non-linear and long-term dependencies                                                   | Computationally heavy, requires tuning, overfitting risk                       |
| **MAR**                     | Adapts to data, interpretable, good with noise                                                 | Limited flexibility, slow with large datasets                                  |
| **RollingRegression**       | Adapts to changing relationships, simple to implement                                          | Window-size sensitivity, struggles with non-linearities, short-term focus      |
| **BallTreeMultivariateMotif** | Efficient pattern discovery, handles large datasets, finds recurring stock price patterns      | Limited forecasting utility, pattern dependency, not suited for volatile data   |

Each model has unique strengths and weaknesses, and the choice depends on the specific characteristics of your stock

Variables Weights:
How to Choose Weights for Stock Market Variables
In stock market predictions, different variables (e.g., Open, Close, Low, High, Volume) can be weighted based on their relevance to your specific forecasting goals. Here’s a breakdown of how each variable might affect your model and how weighting them can change your predictions:

Open Price:

Effect: The Open price often reflects market sentiment from after-hours trading and overnight news.
Weighting: If your focus is on intraday or short-term predictions, you may want to assign a moderate weight to this variable, as it sets the starting point for the trading day but doesn't fully capture market dynamics.
Close Price:

Effect: The Close price is the most commonly used variable in stock forecasting since it represents the final price at which a stock was traded during the regular session.
Weighting: This is typically given more weight (higher value in the weights dictionary) because the Close price consolidates the day's market activities. Higher weight means that the model will focus more on accurately predicting closing prices, which is useful for end-of-day traders.
Low Price:

Effect: The Low price during a trading session gives insight into the support level for a stock.
Weighting: If your use case involves identifying buy signals or price dips, you might want to assign a higher weight to the Low price. For general stock prediction, you can assign it a lower weight since it may be less informative than the Close price.
High Price:

Effect: The High price can signal resistance levels during a trading session.
Weighting: If your strategy involves recognizing overbought conditions or resistance levels, the High price could be given a moderate weight. Otherwise, you might consider giving it the same weight as the Low price for balanced forecasting.
Volume:

Effect: Volume represents the total number of shares traded and is a critical factor in technical analysis, as it reflects market participation and liquidity.
Weighting: Volume can be highly important for volatility and trend analysis, so if you're interested in predicting price movements that are driven by large market participation (e.g., breakouts, crashes), you should assign a higher weight to this variable. Volume spikes often precede significant price changes.




Scenario 1: Intraday Trading Prediction
Use Case: If you're focusing on short-term price movements (e.g., intraday trading), the Open, High, and Volume may be more important than the Close price.



Scenario 2: End-of-Day Prediction
Use Case: If your focus is on end-of-day trading, the Close price will likely be your key target.



Scenario 3: Volatility and Breakout Prediction
Use Case: If you're trying to predict breakouts or periods of high volatility, Volume and High prices may be the most relevant.

Apple Inc. (AAPL) - Technology
Microsoft Corporation (MSFT) - Technology
Johnson & Johnson (JNJ) - Healthcare
Pfizer Inc. (PFE) - Healthcare
JPMorgan Chase & Co. (JPM) - Financials
Visa Inc. (V) - Financials
Amazon.com, Inc. (AMZN) - Consumer Discretionary
Tesla, Inc. (TSLA) - Consumer Discretionary
Procter & Gamble Co. (PG) - Consumer Staples
Coca-Cola Company (KO) - Consumer Staples
Exxon Mobil Corporation (XOM) - Energy
Chevron Corporation (CVX) - Energy
Boeing Co. (BA) - Industrials
American Tower Corporation (AMT) - Real Estate
Duke Energy Corporation (DUK) - Utilities
"""